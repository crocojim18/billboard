{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weird Titles of Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music is a huge genre and is filled with all sorts of weird song titles. Luckily, I have a web-scraped list of all the songs that have been on the _Billboard_ Hot 100, which I can run tests on to find the weirdest song titles out there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Maximize Hapax Legomena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first idea I had was to find songs with large amounts of [hapax legomena](https://en.wikipedia.org/wiki/Hapax_legomenon). Luckily, `nltk` has a hapax legomenon feature built in, which I can easily utilize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = open(\"songlist.txt\")\n",
    "songlist = json.loads(fi.read())\n",
    "fi.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, I'm going to compare all of the titles in the lowercase so there will be more matches. The `nltk` tokenizer takes in a string, so I need to convert the list to a single string first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTitles = \"\"\n",
    "for i in songlist:\n",
    "    allTitles += i.lower() + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Poor Little Fool', 'I Got A Feeling', 'Lonesome Town', 'Never Be Anyone Else But You', \"It's Late\", 'Just A Little Too Much', 'Sweeter Than You', 'I Wanna Be Loved', 'Mighty Good', 'Young Emotions', 'Right By My Side', \"I'm Not Afraid\", \"Yes Sir, That's My Baby\", 'You Are The Only One', 'Milk Cow Blues', \"Travelin' Man\", 'Hello Mary Lou', \"If You Can't Rock Me\", 'Old Enough To Love', 'Patricia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pprint\n",
    "songlist[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poor little fool i g'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTitles[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poor', 'little', 'fool', 'i', 'got', 'a', 'feeling', 'lonesome', 'town', 'never', 'be', 'anyone', 'else', 'but', 'you', 'it', \"'s\", 'late', 'just', 'a']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = nltk.word_tokenize(allTitles)\n",
    "toks[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the song titles are tokenized, we will create a frequency distribution which will allow us to find all the hapax legomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqy = nltk.FreqDist(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3777), ('you', 3352), ('i', 3114), ('love', 2237), ('(', 2047), (')', 2045), ('me', 1934), ('a', 1746), ('to', 1589), ('it', 1520), (\"n't\", 1449), (\"'s\", 1397), ('of', 1353), ('my', 1349), ('do', 1262), ('in', 1249), (\"'\", 1144), ('on', 934), (',', 895), ('your', 767)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqy.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guaglione', 'splish', 'beachcomber', 'artificial', 'multiplication', 'hunk', 'to-night', 'rock-a-hula', 'sender', 'witchcraft', 'cousins', 'spinout', 'legged', \"rebel-'rouser\", 'ramrod', 'kind-a', 'shazam', 'pepe', 'yak', 'besame']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqy.hapaxes()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test before I deal with all of the Big Data™, I will make up a song title and determine the number of hapax legomena in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTitle = \"splish of the pepe yak boy\"\n",
    "hapaxes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTok = nltk.word_tokenize(testTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testTok:\n",
    "    if i in freqy.hapaxes():\n",
    "        hapaxes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've tested that method, I think I'm ready to find the songs with the maximum number of hapax legomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxNum = 0\n",
    "maxList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapList = freqy.hapaxes()\n",
    "for song in songlist:\n",
    "    hapaxes = 0\n",
    "    thisTok = nltk.word_tokenize(song.lower())\n",
    "    for token in thisTok:\n",
    "        if token in hapList:\n",
    "            hapaxes += 1\n",
    "    if hapaxes > maxNum:\n",
    "        maxNum = hapaxes\n",
    "        maxList = [song]\n",
    "    elif hapaxes == maxNum:\n",
    "        maxList.append(song)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Anaheim, Azusa & Cucamonga Sewing Circle, Book Review And Timing Associ', 'Itsy Bitsy Teenie Weenie Yellow Polkadot Bikini']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two songs have 6 hapax legomena! They are Jan & Dean's 1964 single [\"The Anaheim, Azusa & Cucamonga Sewing Circle, Book Review And Timing Association\"](https://www.youtube.com/watch?v=5TAnOCAd_2I), and Brian Hyland's hit 1960 [\"Itsy Bitsy Teenie Weenie Yellow Polkadot Bikini\"](https://www.youtube.com/watch?v=n56E3kScoN8). With both songs being from the 60's, I guess they don't make 'em like they used to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something I never noticed was that long song titles seem to be cut off somewhere in the process (perhaps even from _Billboard_ itself). I may have to take this into account in later experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, I was curious what songs had 5 hapax legomena, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapaxDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for song in songlist:\n",
    "    hapaxes = 0\n",
    "    thisTok = nltk.word_tokenize(song.lower())\n",
    "    for token in thisTok:\n",
    "        if token in hapList:\n",
    "            hapaxes += 1\n",
    "    if hapaxes not in hapaxDict:\n",
    "        hapaxDict[hapaxes] = []\n",
    "    hapaxDict[hapaxes].append(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Jeremiah Peabody's Poly Unsaturated Quick Dissolving Fast Acting Pleasant T\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxDict[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Ray Stevens' [\"Jeremiah Peabody's Poly Unsaturated Quick Dissolving Fast Acting Pleasant Tasting Green & Purple Pills\"](https://www.youtube.com/watch?v=2GB4Km706gM). This one was significantly cut off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bei Mir Bist Du Schön', 'Ungena Za Ulimwengu (Unite The World)', '(A Ship Will Come) Ein Schiff Wird Kommen', 'Pearly Shells (Popo O Ewa)', 'Thank You Falettinme Be Mice Elf Agin/Everybody Is A Star', 'Roland The Roadie And Gertrude The Groupie', 'Tarzan Boy (From \"Teenage Mutant Ninja Turtles III\")', 'Jeeps, Lex Coups, Bimaz & Benz']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxDict[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, a lot of foreign title songs go into this category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I wasn't sure how big each list would be, so I used `len` out of an abundance of caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hapaxDict[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['She Say (Oom Dooby Doom)',\n",
       " 'Baubles, Bangles And Beads',\n",
       " 'The Hawaiian Wedding Song (Ke Kali Nei Au)',\n",
       " \"Great Gosh A'mighty (Down & Out In Bev. Hills Theme)\",\n",
       " 'Ame Caline (Soul Coaxing)',\n",
       " 'Hither And Thither And Yon',\n",
       " 'To The Door Of The Sun (Alle Porte Del Sole)',\n",
       " \"There's A Star Spangled Banner Waving #2 (The Ballad Of Francis Powers)\",\n",
       " 'Sie Liebt Dich (She Loves You)',\n",
       " 'Riki Tiki Tavi',\n",
       " \"Pandora's Golden Heebie Jeebies\",\n",
       " 'Names, Tags, Numbers & Labels',\n",
       " 'D. W. Washburn',\n",
       " 'Les Bicyclettes De Belsize',\n",
       " 'Roosevelt And Ira Lee (Night of the Mossacin)',\n",
       " 'Mozart Symphony No. 40 In G Minor K.550, 1st Movement',\n",
       " 'Invasion Of The Flat Booty B*****s',\n",
       " 'Shamrocks And Shenanigans (Boom Shalock Lock Boom)',\n",
       " 'ESPN Presents The Jock Jam',\n",
       " 'Leflaur Leflah Eshkushka',\n",
       " 'Woo-Hah!! Got You All In Check/Everything Remains Raw',\n",
       " 'Wu-Wear: The Garment Renaissance (From \"High School High\")',\n",
       " 'Do You Know? (The Ping Pong Song)/Dimelo',\n",
       " 'Purest Of Pain (A Puro Dolor)',\n",
       " 'Ni Una Sola Palabra',\n",
       " 'Quitame Ese Hombre',\n",
       " 'Thnks Fr Th Mmrs',\n",
       " 'Ay Chico (Lengua Afuera)',\n",
       " 'Sleazy Remix 2.0 Get Sleazier',\n",
       " 'W O R K I N  M E']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pprint\n",
    "hapaxDict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23984"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hapaxDict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a breakdown of how many items each category has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23984 songs have 0 hapax legomena\n",
      "3879 songs have 1 hapax legomena\n",
      "410 songs have 2 hapax legomena\n",
      "30 songs have 3 hapax legomena\n",
      "8 songs have 4 hapax legomena\n",
      "1 songs have 5 hapax legomena\n",
      "2 songs have 6 hapax legomena\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(\"{1} songs have {0} hapax legomena\".format(i, len(hapaxDict[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, I found some weird songs, truly, but I feel there may be better ways to find weird song titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
